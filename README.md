# multi-dialect-speech-recognition

Considering the current Chinese dialect speech recognition applications in the identification of a single type of dialect, the model volume of high migration costs, intelligent results in fewer areas of application and other pain points, the goal of this project is to achieve a recognition of different dialects and translate them into text expression of the diversity of speech recognition system, and at the same time, through the product of the development of a lightweight basic functional model to provide efficient and convenient solutions for a variety of different application scenarios, in order to make a contribution to the landing of Chinese dialect recognition technology, but also to provide assistance for the protection of local dialects and the enjoyment of people's intelligent achievements. At the same time, through the development of the lightweight basic function model of this product, we can provide efficient and convenient solutions for more different application scenarios, form a comprehensive and perfect Chinese multi-dialect speech recognition function system, and do our best for the landing of the Chinese dialect recognition technology, and at the same time, we can also provide assistance for the protection of the local dialect and the enjoyment of people's intelligent achievements, which can play a series of important socio-cultural values.

If you, like me at the very beginning of this project, lack practical experience in ASR and other related fields, please learn about the research first. One of the highly recommended learning content is the following two papers and related experiments: "**HuBERT: Self-Supervised Speech Representation Learning by Masked Prediction of Hidden Units**" and **"wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations**", because our technical idea of the project has been greatly inspired by them.

At the same time, at the beginning of project 1, in order to quickly learn from the development experience, we reproduced the Chinese version of the pre-trained HuBERT model based on 10,000 hours of data training by WenetSpeech, which was jointly released by Tencent Games' Zhiqi AI team and Northwestern Polytechnical University.

Here are our technical thoughtsï¼š

